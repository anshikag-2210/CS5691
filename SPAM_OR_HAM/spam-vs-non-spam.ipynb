{"cells":[{"metadata":{"_uuid":"c495025c-06b6-457d-b2de-08e99e613989","_cell_guid":"68ac9771-37f5-4232-b5a1-f32688aba567","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nfrom collections import defaultdict\nfrom sklearn.model_selection import train_test_split\nimport glob\nimport re","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62fa5623-c0c1-42b4-b56a-6c3c3dc6cbd8","_cell_guid":"9b8c1fb0-2b0e-4ec1-90d4-508d16b0a8e9","trusted":true},"cell_type":"code","source":"#insert the appropriate path of the dataset of your choice for training\n\n#Please insert the appropriate path of the given dataset here\npath_of_dataset = \"../input/spam-or-not-spam-dataset/spam_or_not_spam.csv\"\n\n\nData = pd.read_csv(path_of_dataset)\nData.head()\nData.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41e05830-0ead-4aa3-ae71-0fe098d333a4","_cell_guid":"9d92de87-0182-40ea-80d2-5f82900a53e9","trusted":true},"cell_type":"code","source":"#Functions\n\n#function to clean the string (pre-processing)\ndef  clean_string(str_arg):\n    cleaned_str=re.sub('[^a-z\\s]+',\" \",str_arg,flags=re.IGNORECASE) \n    cleaned_str=re.sub('(\\s+)',\" \",cleaned_str)\n    cleaned_str=cleaned_str.lower() \n    return cleaned_str\n\n\n#add words of email to bow_dicts\ndef add_To_Bag_of_Words(example,dict_index,bow_dicts):\n        if isinstance(example,np.ndarray): example=example[0]\n        for token_word in example.split(): \n            bow_dicts[dict_index][token_word]+=1\n            \n\n#calculate posterior probability for each class\ndef getTestMailProbability(test_example, cats_info):\n    likelihood_prob=np.zeros(classes.shape[0]) #to store probability w.r.t each class\n    for cat in classes: \n        for test_token in test_example.split(): #split the test example and get p of each test word\n            test_token_counts=cats_info[cat][0].get(test_token,0)+1\n            #now get likelihood of this test_token word                              \n            test_token_prob=test_token_counts/float(cats_info[cat][2])                              \n            #remember why taking log? To prevent underflow!\n            likelihood_prob[cat]+=np.log(test_token_prob)\n            \n    post_prob=np.empty(classes.shape[0])\n    for cat in classes:\n        post_prob[cat]=likelihood_prob[cat]+np.log(cats_info[cat][1])\n    return post_prob\n\n#classifying for an example if spam or ham\ndef get_prediction(example, predictions, cats_info):\n        #preprocess the test example the same way we did for training set examples \n        cleaned_example=clean_string(str(example)) \n        #get the posterior probability of every example                                  \n        post_prob=getTestMailProbability(cleaned_example, cats_info) #get prob of this example for both classes\n        predictions.append(classes[np.argmax(post_prob)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9af71f18-277a-41ff-bc53-c6180ecfc764","_cell_guid":"63a03475-6a79-4857-80f4-ca1ad30156ea","trusted":true},"cell_type":"code","source":"#split data in train data and test data for training and testing\n# taking 20% of the examples from the data set as testing examples\n\ntrain, test= train_test_split(Data, test_size=0.2)\ntrain.columns =[\"Training Examples\",\"Training Labels\"] \ntest.columns =[\"Testing Examples\",\"Testing Labels\"]\n\n#separating the data and labels of both the training and testing examples\ntrain_data=train[\"Training Examples\"]\ntrain_labels=train[\"Training Labels\"]\ntest_data=test[\"Testing Examples\"]\ntest_labels=test[\"Testing Labels\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ffe85e0-c985-47bb-acd2-67356adfe443","_cell_guid":"fb1a7fb7-e764-4e22-9c56-9209c1a7c360","trusted":true},"cell_type":"code","source":"#finding the unique labels\n\nclasses=np.unique(train_labels)\nprint(\"unique labels:\", classes)\n\n#creating bag of words\nbow_dicts=np.array([defaultdict(lambda:0) for index in range(classes.shape[0])])\nif not isinstance(train_data,np.ndarray): train_data=np.array(train_data)\nif not isinstance(train_labels,np.ndarray):train_labels=np.array(train_labels)\n\nfor cat in classes:\n    all_cat_examples=train_data[train_labels==cat]\n    cleaned_examples=[clean_string(str(cat_example)) for cat_example in all_cat_examples]\n    cleaned_examples=pd.DataFrame(data=cleaned_examples)\n    np.apply_along_axis(add_To_Bag_of_Words,1,cleaned_examples,cat,bow_dicts)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31e8e3ef-d26b-4993-8d68-54702f3eafa0","_cell_guid":"c084092e-f770-47cf-ad6a-ba9340eea2a2","trusted":true},"cell_type":"code","source":"prob_classes=np.empty(classes.shape[0])\nall_words=[]\ncat_word_counts=np.empty(classes.shape[0])\n\nfor cat in classes:\n    prob_classes[cat]=np.sum(train_labels==cat)/float(train_labels.shape[0])\n    #Calculating total counts of all the words of each class \n    count=list(bow_dicts[cat].values())\n    cat_word_counts[cat]=np.sum( np.array( list(bow_dicts[cat].values()) ))+1 # |v| is remaining to be added\n    #get all words of this category \n    print(cat_word_counts)\n    all_words+=bow_dicts[cat].keys()\n    \nvocab=np.unique(np.array(all_words))\nvocab_length=vocab.shape[0]\ndenoms=np.array([cat_word_counts[cat]+vocab_length+1 for cat in classes])\ncats_info=[(bow_dicts[cat],prob_classes[cat],denoms[cat]) for cat in classes]                               \ncats_info=np.array(cats_info)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29c62691-8cde-4b3e-afc0-6ec135985e12","_cell_guid":"4dd39377-bb0f-4bad-b2ec-9890faaff278","trusted":true},"cell_type":"code","source":"predictions=[] #to store prediction of each test email\n\nfor example in test_data: \n    get_prediction(example, predictions, cats_info)\n    \npclasses=np.array(predictions)\ntest_acc=np.sum(pclasses==test_labels)/float(test_labels.shape[0]) \nprint (\"Test Set Examples: \",test_labels.shape[0])\nprint (\"Test Set Accuracy: \",test_acc*100,\"%\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90bc3ebb-e026-4617-8881-75d5ce3a74e7","_cell_guid":"05b4899d-a38c-4694-b3b9-eeb3e5300dc4","trusted":true},"cell_type":"code","source":"def desiredFunction(path_of_test_email_folder, cats_info):\n    total_test_files = len(glob.glob1(path_of_test_email_folder,\"*.txt\"))\n\n    predictions=[] #to store prediction of each test example\n    for i in range(1,total_test_files+1):\n        fpath = path_of_test_email_folder + \"/email\" +str(i) + \".txt\"\n        f=open(fpath, \"r\")\n        if f.mode == 'r':\n            example =f.read()\n        get_prediction(example, predictions, cats_info)\n    pclass=np.array(predictions)   \n\n\n    path_of_test_email_folder = \"/kaggle/working/\"\n    \n    path_of_output_file = path_of_test_email_folder + \"/output.txt\"\n    output_file = open(path_of_output_file, 'w') \n\n    col_name=\"test_email\"+ \"       \" + \"spam(1)/ham(0)\\n\\n\\n\"\n    output_file.write(col_name)\n\n    print(col_name)\n    for i in range(0,len(pclass)):\n        email=\"  email\"+str(i+1)+\"                \"+str(pclass[i])+\"\\n\"\n        output_file.write(email)\n        print(email)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e2fe193-4316-4ff6-b77c-659e0e8e660e","_cell_guid":"e924d7bf-3f53-46c8-be8d-aff242a3ee9f","trusted":true},"cell_type":"code","source":"# Insert appropriate path of test folder\n# path = \"test\"\npath = \"../input/dataset\"\ndesiredFunction(path, cats_info)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}